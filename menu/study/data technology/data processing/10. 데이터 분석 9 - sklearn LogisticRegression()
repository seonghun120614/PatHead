class sklearn.linear_model.LogisticRegression(penalty='l2', *, dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)

우리는 이제 모델을 생성하고, 학습을 하기 전까지 왔다. 전처리가 끝나고, 수치 데이터는 정리가 되었으며, categorical data와 통합하여 X, y의 처리가 끝났다. 다음으로 가장 모델중에 초기에 배우는 LogisticRegression을 이용하여 데이터를 주고 학습시키는 과정을 수행한다.

사실 전부 자세히 안 들여다봐도 되는데, 그 이유는 그냥 X와, y 훈련 데이터 셋만 넣어주면 자기 알아서 다 해준다. 즉 하나의 코드만 실행하면 끝이라는 소리이다. 그래도 공부하는 입장에서 그렇게 간단하게만 넘어가면 기억에 잘 남지 않으니, 나는 penalty, dual, tol, C, fit_intercept, intercept_scaling, class_weight, random_state, solver, max_iter, multi_class, verbose, warm_start, n_jobs, l1_ratio 전부 다 보자.

우선 중요한 것부터 본다.

Parameters : 

penalty : {‘l1’, ‘l2’, ‘elasticnet’, ‘none’}, default=’l2’
Used to specify the norm used in the penalization. The ‘newton-cg’, ‘sag’ and ‘lbfgs’ solvers support only l2 penalties. ‘elasticnet’ is only supported by the ‘saga’ solver. If ‘none’ (not supported by the liblinear solver), no regularization is applied. 기본은 l2로 잡혀 있고, 이는 편차 제곱 방식으로 패널티를 준다는 소리이다. 즉 costfunction은 편차 제곱 합일 것이고, 이를 통해 점과 직선 사이의 거리를 줄이면서 linear regression을 수행한다. penalty는 각 4개의 attributes가 있다. 그만큼 costfunction을 다르게 잡아서 수행할 수 있다는 소리이다. 영어를 해석해보면 newton-cg, sag, lbfgs방식의 solver로 인자를 지정하면 l2 penalty만 사용할 수 있고, elasticnet은 오직 saga만 solver인자로 쓸 수 잇으며, 만약 none으로 잡으면 regularization이 적용되지 않는다... 즉 정규화가 되지 않은 상태로, penalty를 준다. 하지만, 실제로 로지스틱 회귀 알고리즘을 사용하기 전에는 반드시 데이터를 정규화 해줘야한다. 여기서 데이터 정규화를 해줘야 하는 이유는 특정 featrue가 다른 feature들을 완전히 지배할 수 있기 때문에 최소 최대 정규화, Z-점수 정규화를 통해 정규화를 진행 후에 무조건 logistic regression을 쓴다.


dual : bool, default=False
Dual or primal formulation. Dual formulation is only implemented for l2 penalty with liblinear solver. Prefer dual=False when n_samples > n_features. n_samples> n_features 일 때 dual =FALSE를 선호하고, 아니면 True를 선호한다. 이건 좀 어려운 얘기인데, 선형 최적화를 위한 이중성 정리를 해야하는데,,, 나도 잘 모르겠다. 해당 위키백과를 참조하기를 바란다.. https://en.wikipedia.org/wiki/Duality_(optimization)#Dual_problem

tol : float, default=1e-4
Tolerance for stopping criteria. 해당 기준이 되면 stop이 된다. 즉 최적의 극값을 찾기 위한 것이다. 그 극값의 +-tol이 되면 멈춘다.

solver : {‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’}, default=’lbfgs’ 해당 regression문제를 푸는 방식을 정할 수 있는데, 속성들은 전부 검색해서 자세히 보길 바란다.. 아마 전문 지식이 필요해 좀 이해하기 힘들 것이다.

max_iter : int, default = 100 기본적으로 100번 반복하며, 더 높게 더 낮게 지정할 수 있다.

verbose : int, default = 0 :
이것 또한 전문 지식이 필요해, 수학적으로 많이 강의를 들어보길 바란다.

여기부터 인자들은 잘 쓰지 않는 인자들이다
multi_class : {‘auto’, ‘ovr’, ‘multinomial’}, default=’auto’
l1_ratio : float, default=None
n_jobs : int, default=None
warm_start : bool, default=False
random_state : int, RandomState instance, default=None
class_weight : dict or ‘balanced’, default=None
intercept_scaling : float, default=1
fit_intercept : bool, default=True
C : float, default=1.0



Attributes : 

classes_ndarray of shape (n_classes, )
A list of class labels known to the classifier.

coef_ : ndarray of shape (1, n_features) or (n_classes, n_features)
Coefficient of the features in the decision function. coef_  is of shape (1, n_features) when the given problem is binary. In particular, when multi_class='multinomial', coef_ corresponds to outcome 1 (True) and -coef_ corresponds to outcome 0 (False). 변수들이 y에 영향을 주는 통계량인 coefficient를 반환해준다. ndarray형태로 반환한다.

intercept_ndarray of shape (1,) or (n_classes,)
Intercept (a.k.a. bias) added to the decision function. If fit_intercept is set to False, the intercept is set to zero. intercept_ is of shape (1,) when the given problem is binary. In particular, when multi_class='multinomial', intercept_ corresponds to outcome 1 (True) and -intercept_ corresponds to outcome 0 (False).



Methods : 

fit(X, y[, sample_weight]) : Fit the model according to the given training data. 모델에 데이터를 넣고, 학습을 합니다.

get_params([deep]) : Get parameters for this estimator.
모수들이 모인 dict를 얻을 수 있다.

predict(X) : Predict class labels for samples in X.
학습된 모델에 X_test를 넣어 예측할 수 있다.

score(X, y[, sample_weight]) : Return the mean accuracy on the given test data and labels.
평균 정확성들을 반환한다. X_test와 y_test만 넣어주면 된다.

set_params(**params)
Set the parameters of this estimator. 파라미터들을 수정가능하다. input은 dict로 함.